model_path: "gpt2"
tokenizer_path: "gpt2"
save_dir: "../ckpts/gpt2-sft"

train_args:
  output_dir: "./results"
  num_train_epochs: 1
  logging_steps: 100
  save_strategy: "no"
  per_device_train_batch_size: 3
  per_device_eval_batch_size: 3
  warmup_steps: 100
  weight_decay: 0.01
  logging_dir: "./logs"
  fp16: True
  bf16: False
  evaluation_strategy: "epoch"

train_data: "../data/datasets/supervised_chosen_batched.jsonl"