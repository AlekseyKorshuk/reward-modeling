model_path: "gpt2-xl"
model_type: "causal"
tokenizer_path: "gpt2"
num_layers_unfrozen: 0.67

train_args:
  output_dir: "temp/gpt2xl-rm"
  num_train_epochs: 1
  logging_steps: 10
  eval_steps: 10
  save_strategy: "epoch"
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  warmup_steps: 100
  weight_decay: 0.01
  learning_rate: 1.0e-5
  save_total_limit: 1
  logging_dir: "./logs"
  fp16: True
  bf16: False

data_path: "AlekseyKorshuk/cup-it-ds-pairwise-small"
trainer_type: "default"
order: [ "0", "1", "2", "3", "4" ]